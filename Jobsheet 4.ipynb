{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac71d259",
   "metadata": {},
   "source": [
    "# JOBSHEET 4 : TEKNIK ANALISIS POSE & GEOMETRI TUBUH PADA GAMBAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ac9d67",
   "metadata": {},
   "source": [
    "## Praktikum D1 — Inisialisasi Kamera dan Akuisisi Citra \n",
    "Tujuan:\n",
    "Mahasiswa mampu menginisialisasi kamera dan menampilkan citra secara real-time sebagai dasar untuk pengolahan visual selanjutnya.\n",
    "Deskripsi:\n",
    "Praktikum ini merupakan tahap awal dalam mengenal sistem visi komputer. Mahasiswa akan belajar membuka perangkat kamera, menampilkan citra secara berkelanjutan, serta memastikan bahwa perangkat keras dan perangkat lunak dapat berkomunikasi dengan baik. Proses ini menjadi fondasi bagi semua eksperimen berikutnya yang menggunakan aliran video sebagai input utama.\n",
    "Langkah:\n",
    "1.\tJalankan skrip Python menggunakan pustaka opencv-python.\n",
    "2.\tInisialisasi kamera dengan cv2.VideoCapture(0).\n",
    "3.\tBaca setiap frame dan tampilkan di jendela preview.\n",
    "4.\tUkur frame per second (FPS) untuk menilai kelancaran akuisisi video.\n",
    "5.\tTekan tombol q untuk menghentikan proses.\n",
    "Indikator Keberhasilan:\n",
    "Citra tampil dengan stabil, FPS berada di atas 10, dan proses dapat dihentikan dengan perintah keluar tanpa error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed303153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "# Inisialisasi kamera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Periksa apakah kamera bisa dibuka\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Kamera tidak bisa dibuka. Coba index 1/2.\")\n",
    "\n",
    "frames, t0 = 0, time.time()\n",
    "\n",
    "while True:\n",
    "    ok, frame = cap.read()\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    frames += 1\n",
    "\n",
    "    # Hitung FPS tiap detik\n",
    "    if time.time() - t0 >= 1.0:\n",
    "        cv2.setWindowTitle(\"Preview\", f\"Preview (FPS ~ {frames})\")\n",
    "        frames, t0 = 0, time.time()\n",
    "\n",
    "    # Tampilkan video real-time\n",
    "    cv2.imshow(\"Preview\", frame)\n",
    "\n",
    "    # Tekan tombol 'q' untuk keluar\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Bersihkan resource\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb912840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell Inspiron\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6edfc628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ cvzone berhasil diimpor!\n"
     ]
    }
   ],
   "source": [
    "from cvzone.PoseModule import PoseDetector\n",
    "print(\"✅ cvzone berhasil diimpor!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5c7385",
   "metadata": {},
   "source": [
    "## Praktikum D2 — Deteksi Pose dan Analisis Sudut Tubuh\n",
    "\n",
    "Tujuan:\n",
    "Mahasiswa mampu menerapkan pose estimation menggunakan MediaPipe dan menghitung sudut sendi tertentu, misalnya sudut lutut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0091bd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from cvzone.PoseModule import PoseDetector\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Kamera tidak bisa dibuka.\")\n",
    "\n",
    "detector = PoseDetector(\n",
    "    staticMode=False,\n",
    "    modelComplexity=1,\n",
    "    enableSegmentation=False,\n",
    "    detectionCon=0.5,\n",
    "    trackCon=0.5\n",
    ")\n",
    "\n",
    "while True:\n",
    "    # Tangkap setiap frame dari webcam\n",
    "    success, img = cap.read()\n",
    "\n",
    "    # Temukan pose manusia dalam frame\n",
    "    img = detector.findPose(img)\n",
    "\n",
    "    # Temukan landmark, bounding box, dan pusat tubuh dalam frame\n",
    "    # Set draw=True untuk menggambar landmark dan bounding box pada gambar\n",
    "    lmList, bboxInfo = detector.findPosition(img, draw=True, bboxWithHands=False)\n",
    "\n",
    "    # Periksa apakah ada landmark tubuh yang terdeteksi\n",
    "    if lmList:\n",
    "        # Dapatkan pusat bounding box di sekitar tubuh\n",
    "        center = bboxInfo[\"center\"]\n",
    "\n",
    "        # Gambar lingkaran di pusat bounding box\n",
    "        cv2.circle(img, center, 5, (255, 0, 255), cv2.FILLED)\n",
    "\n",
    "        # Hitung jarak antara landmark 11 dan 15 dan gambarkan pada gambar\n",
    "        length, img, info = detector.findDistance(\n",
    "            lmList[11][0:2],\n",
    "            lmList[15][0:2],\n",
    "            img=img,\n",
    "            color=(255, 0, 0),\n",
    "            scale=10\n",
    "        )\n",
    "\n",
    "        # Hitung sudut antara landmark 11, 13, dan 15 dan gambarkan pada gambar\n",
    "        angle, img = detector.findAngle(\n",
    "            lmList[11][0:2],\n",
    "            lmList[13][0:2],\n",
    "            lmList[15][0:2],\n",
    "            img=img,\n",
    "            color=(0, 0, 255),\n",
    "            scale=10\n",
    "        )\n",
    "\n",
    "        # Periksa apakah sudut mendekati 50 derajat dengan offset 10\n",
    "        isCloseAngle50 = detector.angleCheck(myAngle=angle, targetAngle=50, offset=10)\n",
    "\n",
    "        # Cetak hasil pemeriksaan sudut\n",
    "        print(isCloseAngle50)\n",
    "\n",
    "    cv2.imshow(\"Pose + Angle\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb88445d",
   "metadata": {},
   "source": [
    "## Praktikum D3 — Deteksi Wajah dan Analisis Kedipan Mata\n",
    "\n",
    "Tujuan:\n",
    "Mahasiswa mampu mendeteksi wajah menggunakan MediaPipe Face Mesh dan mengukur perubahan jarak antar landmark mata untuk mendeteksi kedipan.\n",
    "\n",
    "Deskripsi:\n",
    "Face Mesh memetakan 468 titik pada wajah, termasuk titik di sekitar mata. Praktikum ini memperkenalkan konsep Eye Aspect Ratio (EAR), yaitu rasio antara jarak vertikal dan horizontal mata yang digunakan untuk menentukan apakah mata dalam kondisi terbuka atau tertutup.\n",
    "Langkah:\n",
    "\n",
    "1.\tGunakan modul mediapipe.solutions.face_mesh.\n",
    "2.\tAmbil koordinat beberapa landmark mata (misalnya 33, 133, 145, dan 159).\n",
    "3.\tHitung Eye Aspect Ratio (EAR):\n",
    "\n",
    "EAR=dvertikaldhorizontalEAR\t=\n",
    "\\frac{d_{vertikal}}{d_{horizontal}}EAR=dhorizontaldvertikal\n",
    "\n",
    "4.\tTampilkan nilai EAR di layar; nilai menurun saat mata tertutup.\n",
    "5.\tImplementasikan ambang batas untuk mendeteksi kedipan otomatis.\n",
    "\n",
    "Indikator Keberhasilan:\n",
    "Sistem mampu menampilkan wajah dengan titik landmark yang stabil dan mendeteksi perubahan nilai EAR secara akurat saat mata berkedip.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4558961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from cvzone.FaceMeshModule import FaceMeshDetector\n",
    "\n",
    "LEFT_EYE = [386, 374, 263, 362]   # top, bottom, left, right\n",
    "RIGHT_EYE = [159, 145, 133, 33]\n",
    "\n",
    "def dist(a, b):\n",
    "    return np.linalg.norm(np.array(a) - np.array(b))\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = FaceMeshDetector(maxFaces=1)\n",
    "\n",
    "blink_count = 0\n",
    "closed_frames = 0\n",
    "CLOSED_FRAMES_THRESHOLD = 2\n",
    "EYE_AR_THRESHOLD = 0.25\n",
    "is_closed = False\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img, faces = detector.findFaceMesh(img, draw=True)\n",
    "\n",
    "    if faces:\n",
    "        face = faces[0]\n",
    "\n",
    "        # EAR kiri\n",
    "        vL = dist(face[LEFT_EYE[0]], face[LEFT_EYE[1]])\n",
    "        hL = dist(face[LEFT_EYE[2]], face[LEFT_EYE[3]])\n",
    "        earL = vL / hL\n",
    "\n",
    "        # EAR kanan\n",
    "        vR = dist(face[RIGHT_EYE[0]], face[RIGHT_EYE[1]])\n",
    "        hR = dist(face[RIGHT_EYE[2]], face[RIGHT_EYE[3]])\n",
    "        earR = vR / hR\n",
    "\n",
    "        ear = (earL + earR) / 2\n",
    "\n",
    "        cv2.putText(img, f\"EAR: {ear:.3f}\", (20, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,255), 2)\n",
    "\n",
    "        if ear < EYE_AR_THRESHOLD:\n",
    "            closed_frames += 1\n",
    "            if closed_frames >= CLOSED_FRAMES_THRESHOLD and not is_closed:\n",
    "                blink_count += 1\n",
    "                is_closed = True\n",
    "        else:\n",
    "            closed_frames = 0\n",
    "            is_closed = False\n",
    "\n",
    "        cv2.putText(img, f\"Blink: {blink_count}\", (20, 80),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2)\n",
    "\n",
    "    cv2.imshow(\"Blink Detection\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786bcc88",
   "metadata": {},
   "source": [
    "## Praktikum D4 — Deteksi Tangan dan Penghitungan Jumlah Jari\n",
    "\n",
    "Tujuan:\n",
    "Mahasiswa mampu mendeteksi tangan manusia dan menghitung jumlah jari yang terangkat menggunakan landmark tangan dari MediaPipe.\n",
    "\n",
    "Deskripsi:\n",
    "MediaPipe Hands mendeteksi 21 landmark pada setiap tangan. Berdasarkan hubungan antara ujung jari (tip) dan sendi bawahnya (PIP), dapat ditentukan apakah jari tersebut dalam posisi terangkat atau tidak. Pendekatan ini digunakan untuk menghitung jumlah jari terbuka.\n",
    "\n",
    "Langkah:\n",
    "\n",
    "1.\tGunakan mediapipe.solutions.hands untuk memperoleh koordinat landmark.\n",
    "2.\tBandingkan posisi tip (ujung jari) terhadap PIP (sendi bawah) berdasarkan sumbu vertikal (y).\n",
    "3.\tTentukan logika sederhana: jika ytip<ypipy_{tip} < y_{pip}ytip<ypip, maka jari dianggap terangkat.\n",
    "4.\tTampilkan jumlah jari yang terangkat di layar.\n",
    "5.\tUji sistem dengan berbagai kombinasi jumlah jari.\n",
    "\n",
    "Indikator Keberhasilan:\n",
    "Jumlah jari yang terangkat terdeteksi dengan benar (akurasi >80%) pada berbagai kondisi pencahayaan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55b09e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Kamera tidak bisa dibuka.\")\n",
    "\n",
    "detector = HandDetector(\n",
    "    staticMode=False,\n",
    "    maxHands=1,\n",
    "    modelComplexity=1,\n",
    "    detectionCon=0.5,\n",
    "    minTrackCon=0.5\n",
    ")\n",
    "\n",
    "while True:\n",
    "    ok, img = cap.read()\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    hands, img = detector.findHands(img, draw=True, flipType=True)\n",
    "\n",
    "    if hands:\n",
    "        hand = hands[0]                     # dict berisi \"lmList\", \"bbox\", dll\n",
    "        fingers = detector.fingersUp(hand)  # list panjang 5 berisi 0/1\n",
    "        count = sum(fingers)\n",
    "\n",
    "        cv2.putText(\n",
    "            img,\n",
    "            f\"Fingers: {count}   {fingers}\",\n",
    "            (20, 40),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.9,\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        )\n",
    "\n",
    "    cv2.imshow(\"Hands + Fingers\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5839f38e",
   "metadata": {},
   "source": [
    "## Praktikum D5 — Pengenalan Gestur Tangan (Hand Gesture Recognition)\n",
    "\n",
    "Tujuan:\n",
    "Mahasiswa mampu mengenali gestur tangan sederhana berdasarkan hubungan geometris antar landmark.\n",
    "\n",
    "Deskripsi:\n",
    "Gestur tangan merupakan salah satu bentuk komunikasi nonverbal yang dapat diterjemahkan oleh sistem visi komputer. Dalam praktikum ini, mahasiswa akan merancang aturan geometris untuk mengenali gestur dasar seperti “Thumbs Up”, “OK”, dan “Rock–Paper– Scissors”.\n",
    "\n",
    "Langkah:\n",
    "\n",
    "1.\tGunakan landmark kunci seperti ujung ibu jari (4), ujung telunjuk (8), pergelangan tangan (0), dan lainnya.\n",
    "2.\tDefinisikan kriteria masing-masing gestur, misalnya:\n",
    "o\tOK: jarak antara ujung ibu jari dan telunjuk < ambang tertentu.\n",
    "o\tThumbs Up: ibu jari mengarah ke atas dan jauh dari pergelangan.\n",
    "o\tRock/Paper/Scissors: menggunakan rata-rata jarak ujung jari ke pergelangan.\n",
    "3.\tTampilkan label gestur yang dikenali pada jendela kamera.\n",
    "4.\tUji dengan beberapa posisi tangan.\n",
    "\n",
    "Indikator Keberhasilan:\n",
    "Sistem dapat mengenali minimal tiga jenis gestur tangan dengan akurasi yang konsisten dan respons waktu <0.3 detik per frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff252a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "\n",
    "def dist(a, b):\n",
    "    return np.linalg.norm(np.array(a) - np.array(b))\n",
    "\n",
    "def classify_gesture(hand):\n",
    "    # hand[\"lmList\"] berisi 21 titik (x,y,z) dalam piksel saat flipType=True\n",
    "    lm = hand[\"lmList\"]\n",
    "\n",
    "    wrist = np.array(lm[0][:2])\n",
    "    thumb_tip = np.array(lm[4][:2])\n",
    "    index_tip = np.array(lm[8][:2])\n",
    "    middle_tip = np.array(lm[12][:2])\n",
    "    ring_tip = np.array(lm[16][:2])\n",
    "    pinky_tip = np.array(lm[20][:2])\n",
    "\n",
    "    # Heuristik jarak relatif\n",
    "    r_mean = np.mean([\n",
    "        dist(index_tip, wrist),\n",
    "        dist(middle_tip, wrist),\n",
    "        dist(ring_tip, wrist),\n",
    "        dist(pinky_tip, wrist),\n",
    "        dist(thumb_tip, wrist)\n",
    "    ])\n",
    "\n",
    "    # Aturan:\n",
    "    if dist(thumb_tip, index_tip) < 35:\n",
    "        return \"OK\"\n",
    "\n",
    "    # Thumbs up: ibu jari tinggi (y kecil), jauh dari wrist\n",
    "    if (thumb_tip[1] < wrist[1] - 40) and (dist(thumb_tip, wrist) > 0.8 * dist(index_tip, wrist)):\n",
    "        return \"THUMBS_UP\"\n",
    "\n",
    "    if r_mean < 120:\n",
    "        return \"ROCK\"\n",
    "\n",
    "    if r_mean > 200:\n",
    "        return \"PAPER\"\n",
    "\n",
    "    if (\n",
    "        dist(index_tip, wrist) > 180 and\n",
    "        dist(middle_tip, wrist) > 180 and\n",
    "        dist(ring_tip, wrist) < 160 and\n",
    "        dist(pinky_tip, wrist) < 160\n",
    "    ):\n",
    "        return \"SCISSORS\"\n",
    "\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Kamera tidak bisa dibuka.\")\n",
    "\n",
    "detector = HandDetector(\n",
    "    staticMode=False,\n",
    "    maxHands=1,\n",
    "    modelComplexity=1,\n",
    "    detectionCon=0.5,\n",
    "    minTrackCon=0.5\n",
    ")\n",
    "\n",
    "while True:\n",
    "    ok, img = cap.read()\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    hands, img = detector.findHands(img, draw=True, flipType=True)\n",
    "\n",
    "    if hands:\n",
    "        label = classify_gesture(hands[0])\n",
    "        cv2.putText(\n",
    "            img,\n",
    "            f\"Gesture: {label}\",\n",
    "            (20, 40),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.9,\n",
    "            (0, 255, 255),\n",
    "            2\n",
    "        )\n",
    "\n",
    "    cv2.imshow(\"Hand Gestures (cvzone)\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beaa310",
   "metadata": {},
   "source": [
    "## Praktikum D6 — Analisis Gerakan Tubuh dan Penghitung Aktivitas Tujuan:\n",
    "Mahasiswa mampu membuat sistem penghitung aktivitas fisik (seperti squat dan push-up) menggunakan data landmark pose dan logika kondisi gerakan.\n",
    "\n",
    "Deskripsi:\n",
    "Praktikum ini mengintegrasikan kemampuan deteksi pose dengan logika analisis gerakan. Mahasiswa akan menerapkan penghitungan sudut dan rasio jarak untuk mengenali dua posisi utama (naik dan turun), serta menerapkan teknik debounce untuk menghindari penghitungan ganda.\n",
    "\n",
    "Langkah:\n",
    "\n",
    "1.\tGunakan MediaPipe Pose untuk mendeteksi titik tubuh yang relevan.\n",
    "2.\tUntuk squat: hitung sudut lutut kiri dan kanan, tentukan kondisi up (θ > 160°) dan\n",
    "down (θ < 80°).\n",
    "3.\tUntuk push-up: gunakan rasio jarak bahu–pergelangan terhadap bahu–pinggul.\n",
    "4.\tImplementasikan logika transisi down → up sebagai satu repetisi.\n",
    "5.\tTampilkan jumlah repetisi dan status posisi di layar secara real-time.\n",
    "\n",
    "Indikator Keberhasilan:\n",
    "Sistem mampu menghitung jumlah gerakan dengan kesalahan di bawah 10% untuk 10–20 repetisi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd71bbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "from collections import deque\n",
    "from cvzone.PoseModule import PoseDetector\n",
    "\n",
    "MODE = \"squat\"      # tekan 'm' untuk toggle ke pushup\n",
    "KNEE_DOWN, KNEE_UP = 80, 160      # ambang squat (deg)\n",
    "DOWN_R, UP_R = 0.85, 1.00         # ambang push-up (rasio)\n",
    "SAMPLE_OK = 4                     # minimal frame konsisten sebelum ganti state\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"Kamera tidak bisa dibuka.\")\n",
    "\n",
    "detector = PoseDetector(staticMode=False, modelComplexity=1,\n",
    "                        enableSegmentation=False, detectionCon=0.5,\n",
    "                        trackCon=0.5)\n",
    "\n",
    "count, state = 0, \"up\"\n",
    "debounce = deque(maxlen=6)\n",
    "\n",
    "def ratio_pushup(lm):\n",
    "    sh = np.array(lm[11][1:3])\n",
    "    wr = np.array(lm[15][1:3])\n",
    "    hp = np.array(lm[23][1:3])\n",
    "    return np.linalg.norm(sh - wr) / (np.linalg.norm(sh - hp) + 1e-8)\n",
    "\n",
    "while True:\n",
    "    ok, img = cap.read()\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    img = detector.findPose(img, draw=True)\n",
    "    lmList, _ = detector.findPosition(img, draw=False)\n",
    "\n",
    "    flag = None\n",
    "\n",
    "    if lmList:\n",
    "        if MODE == \"squat\":\n",
    "            angL, img = detector.findAngle(\n",
    "                lmList[23][0:2],\n",
    "                lmList[25][0:2],\n",
    "                lmList[27][0:2],\n",
    "                img=img,\n",
    "                color=(0, 0, 255),\n",
    "                scale=10\n",
    "            )\n",
    "\n",
    "            angR, img = detector.findAngle(\n",
    "                lmList[24][0:2],\n",
    "                lmList[26][0:2],\n",
    "                lmList[28][0:2],\n",
    "                img=img,\n",
    "                color=(0, 255, 0),\n",
    "                scale=10\n",
    "            )\n",
    "\n",
    "            ang = (angL + angR) / 2.0\n",
    "\n",
    "            if ang < KNEE_DOWN:\n",
    "                flag = \"down\"\n",
    "            elif ang > KNEE_UP:\n",
    "                flag = \"up\"\n",
    "\n",
    "            cv2.putText(img, f\"Knee: {ang:5.1f}\", (20, 70),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)\n",
    "\n",
    "        else:\n",
    "            r = ratio_pushup(lmList)\n",
    "\n",
    "            if r < DOWN_R:\n",
    "                flag = \"down\"\n",
    "            elif r > UP_R:\n",
    "                flag = \"up\"\n",
    "\n",
    "            cv2.putText(img, f\"Ratio: {r:4.2f}\", (20, 70),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,255), 2)\n",
    "\n",
    "    debounce.append(flag)\n",
    "\n",
    "    if debounce.count(\"down\") >= SAMPLE_OK and state == \"up\":\n",
    "        state = \"down\"\n",
    "\n",
    "    if debounce.count(\"up\") >= SAMPLE_OK and state == \"down\":\n",
    "        state = \"up\"\n",
    "        count += 1\n",
    "\n",
    "    cv2.putText(img, f\"Mode: {MODE.upper()} Count: {count}\", (20, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2)\n",
    "\n",
    "    cv2.putText(img, f\"State: {state}\", (20, 100),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "\n",
    "    cv2.imshow(\"Pose Counter\", img)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    if key == ord('m'):\n",
    "        MODE = \"pushup\" if MODE == \"squat\" else \"squat\"\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
